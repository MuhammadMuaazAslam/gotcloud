#-----------------------------------
# General Defaults
# This configuration file contains 
# the default run-time configuration.
# The user configuration file is read
# prior to reading this file. Only
# keys that have not yet been set are
# read from this file, preserving the
# user configuration values.
#-----------------------------------
#########################
# References
#########################
REF_DIR = $(GOTCLOUD_ROOT)/gotcloud.ref
AS = NCBI37
REF = $(REF_DIR)/hs37d5.fa
DBSNP_VCF =  $(REF_DIR)/dbsnp_142.b37.vcf.gz
HM3_VCF = $(REF_DIR)/hapmap_3.3.b37.sites.vcf.gz
OMNI_VCF = $(REF_DIR)/1000G_omni2.5.b37.sites.PASS.vcf.gz
INDEL_PREFIX = $(REF_DIR)/1kg.pilot_release.merged.indels.sites.hg19 # 1000 Genomes Pilot 1 indel VCF prefix
PE_ANN = $(REF_DIR)/pe.100.01.ann
SE_ANN = $(REF_DIR)/se.100.005.ann
MOSAIK_JMP = $(REF_DIR)/
#----------
# CRAM MD5 ref file defaults
#----------
# Set this to where you already have MD5 files generated or 
# where you want them generated.
MD5_DIR = $(REF_DIR)/md5/
MD5_SCRIPT = $(SCRIPT_DIR)/seq_cache_populate.pl


##############
# BINARIES
##############
BIN_DIR = $(GOTCLOUD_ROOT)/bin
SCRIPT_DIR = $(GOTCLOUD_ROOT)/scripts

BASE_PREFIX = 

#-----------------------------------
# Common Defaults
#-----------------------------------
MAKE_OPTS =  # Set additional settings for running the makefile

#OUT_DIR=
#INPUT_ROOT=
BAM_LIST=$(OUT_DIR)/bam.list

# By default, when reading BAMs, the sample ID is checked that it matches the
# sample id for that BAM found in the input BAM_LIST.
# Turn off this validation by setting IGNORE_SM_CHECK to something.
IGNORE_SM_CHECK=


#-----------------------------------
# Alignment Specific Defaults
#-----------------------------------
FASTQ_PREFIX =
FASTQ_LIST = 

#Set the maper type
MAP_TYPE = BWA_MEM

#########################
# Output Directory
#########################
FINAL_BAM_DIR = $(OUT_DIR)/bams

##############
# BINARIES
##############
SAMTOOLS_EXE = $(BIN_DIR)/samtools
SAMTOOLS_SORT_EXE = $(BIN_DIR)/samtools
BWA_EXE = $(BIN_DIR)/bwa
VERIFY_BAM_ID_EXE = $(BIN_DIR)/verifyBamID
QPLOT_EXE = $(BIN_DIR)/qplot
BAM_EXE = $(BIN_DIR)/bam
MOSAIK_ALIGN_EXE = $(BIN_DIR)/MosaikAligner
MOSAIK_BUILD_EXE = $(BIN_DIR)/MosaikBuild
PREMO_EXE = $(BIN_DIR)/premo

####################
# Alignment Info
####################
SORT_MAX_MEM = 2000000000

########################
# Temporary Directories
########################
TMP_DIR = $(OUT_DIR)/tmp
SAI_TMP = $(TMP_DIR)/bwa.sai.t
ALN_TMP = $(TMP_DIR)/alignment.aln
POL_TMP = $(TMP_DIR)/alignment.pol
MERGE_TMP = $(TMP_DIR)/alignment.pol
DEDUP_TMP = $(TMP_DIR)/alignment.dedup
RECAL_TMP = $(TMP_DIR)/alignment.recal
QC_DIR = $(OUT_DIR)/QCFiles
MKB_TMP = $(TMP_DIR)/mosaikBuild

####################
# BWA Parameters
####################
BWA_THREADS = -t 1
BWA_QUAL = -q 15
ONE_BWA = 0
BWA_RM_FASTQ = 

########################
# Mosaik Parameters 
########################
MOSAIK_HS = -hs 15
MOSAIK_MHP = -mhp 150
MOSAIK_THREADS = -p 1

########################
# Polish Settings
########################
polish_CMD=$(BAM_EXE) polishBam -f $(REF) --AS $(AS) --UR file:$(REF) --checkSQ -i $(basename $^) -o $(basename $@) -l $(basename $@).log $(BAMUTIL_THINNING)

########################
# Post-Merge Steps
########################
PER_MERGE_STEPS = verifyBamID qplot index recab
ALIGN_CRAM_OUTPUT_STEPS = cramIndex cram

### To output cram instead of BAM from the alignment pipeline, set ALIGN_CRAM_OUTPUT = TRUE:
ALIGN_CRAM_OUTPUT = false

merge_EXT = merged.bam
merge_DIR = $(MERGE_TMP)


# To separate dedup & recab into 2 steps, and plot them, use:
#PER_MERGE_STEPS = verifyBamID qplot index recab dedup
#recab_RUN_DEDUP = 
#recab_DEPEND = dedup
#qplot_DEPEND = recab dedup
#qplot_LABELS = recal,dedup

dedup_DEPEND = merge
dedup_REQ_EXES = $(BAM_EXE)
dedup_EXT = dedup.bam
dedup_DIR = $(DEDUP_TMP)
dedup_USER_PARAMS = 
dedup_PARAMS =  --log $(basename $@).metrics
dedup_CMD=$(BAM_EXE) dedup --in $(basename $^) --out $(basename $@) $(dedup_PARAMS) $(dedup_USER_PARAMS) $(BAMUTIL_THINNING)
dedup_RMDEP = 1

recab_DEPEND = merge
recab_REQ_EXES = $(BAM_EXE)
recab_EXT = recal.bam
recab_DIR = $(FINAL_BAM_DIR)
recab_STORE_OQ = # Uncommment to store OQ: --storeQualTag OQ 
recab_BINNING = 
recab_PARAMS =  --refFile $(REF) --dbsnp $(DBSNP_VCF) $(recab_STORE_OQ) $(recab_BINNING)
recab_USER_PARAMS = 
recab_RUN_DEDUP = dedup $(dedup_PARAMS) $(dedup_USER_PARAMS) --
recab_OUT = $(basename $@)
recab_CMD=$(BAM_EXE) $(recab_RUN_DEDUP)recab --in $(basename $^) --out $(recab_OUT) $(recab_PARAMS) $(recab_USER_PARAMS) $(BAMUTIL_THINNING) $(GEN_CRAM)
recab_RMDEP = 1
GEN_CRAM = 

index_DEPEND = recab
index_REQ_EXES = $(SAMTOOLS_EXE)
index_EXT = $(recab_EXT).bai
index_DIR = $(FINAL_BAM_DIR)
index_CMD = $(SAMTOOLS_EXE) index $(basename $^)

qplot_DEPEND = recab
qplot_REQ_EXES = $(QPLOT_EXE)
qplot_EXT = qplot
qplot_DIR = $(QC_DIR)
qplot_LABELS = recal
qplot_MIN_MAP_QUAL = --minMapQuality 0
qplot_IN =  $(basename $^)
qplot_CMD = $(VIEW_CRAM) $(QPLOT_EXE) --reference $(REF) --dbsnp $(DBSNP_VCF) --stats $(basename $@).stats --Rcode $(basename $@).R $(qplot_MIN_MAP_QUAL) --bamlabel $(qplot_LABELS) $(qplot_IN)
VIEW_CRAM = 

verifyBamID_DEPEND = recab index
verifyBamID_REQ_EXES = $(VERIFY_BAM_ID_EXE)
verifyBamID_EXT = genoCheck
verifyBamID_DIR = $(QC_DIR)
verifyBamID_PARAMS = --vcf $(HM3_VCF)
verifyBamID_USER_PARAMS = 
verifyBamID_CMD = $(VERIFY_BAM_ID_EXE) --bam $(basename $<) --out $(basename $@) $(verifyBamID_PARAMS) $(verifyBamID_USER_PARAMS)

# Only convert & remove BAM after verifyBamID & qplot are done with it.
cram_DEPEND = recab index verifyBamID qplot
cram_REQ_EXES = $(SAMTOOLS_EXE)
cram_EXT = cram
cram_DIR = $(FINAL_BAM_DIR)
cram_CMD = $(SAMTOOLS_EXE) view -C -T $(REF) $(basename $<) > $(basename $@)
cram_RMDEP = 1  # Unset this/set to 0 if you want to keep the BAMs.

cramIndex_DEPEND = cram
cramIndex_REQ_EXES = $(SAMTOOLS_EXE)
cramIndex_EXT = cram.crai
cramIndex_DIR = $(FINAL_BAM_DIR)
cramIndex_CMD = $(SAMTOOLS_EXE) index $(basename $^)

#-----------------------------------
# Variant Calling Specific Defaults
#-----------------------------------
BAM_PREFIX = 
##################################################################
# GOTCLOUD_ROOT is defined in the script prior to reading any configuration and is
# set to one directory above the umake.pl script.
###############################################################################
## REQUIRED ELEMENTS FOR THE USER TO SET VIA CONF OR PARAMETERS
###############################################################################
CHRS = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X  # List of chromosomes to call SNPs. For multiple chromosomes, separate by whitespace
###############################################################################
## Optional Settings 
###############################################################################
MAKE_BASE_NAME = umake  # basename of output Makefile $(MAKE_BASE_NAME).<type>.Makefile will be generated
#PED_INDEX = $(INPUT_ROOT)/umake-example.ped    # SAMPLE PED FILE (required only for chrX calling)
#
###############################################################################
## ARGUMENT FOR VCF FILTERING
###############################################################################
# The following set of values are used for applying filters to the VCF.
# To remove a filter, set it to blank or off in your user configuration file

# The following values set the min/max depth filter.
# The minDP filter is calculated using FILTER_MIN_SAMPLE_DP * numSamples or 
# The maxDP filter is calculated using FILTER_MAX_SAMPLE_DP * numSamples or 
FILTER_MAX_SAMPLE_DP = 1000 # Max Depth per Sample
FILTER_MIN_SAMPLE_DP = 1  # Min Depth per Sample

# Filter on the minimum number of samples - based on a fraction of the
# total number of samples.  This will only be used if FILTER_MIN_NS is not set.
FILTER_MIN_NS_FRAC = .50
FILTER_MIN_NS = 


# To remove a filter, set it to blank or "off" in your user configuration file
# The values of these filters must be numbers (or comma/space separated list of numbers
# These rules apply to the following filters:
#   Specifying 1 value in the filter will turn that filter on and use that value.
#   Specifying 2 values in the filter (separated by ',' and/or ' ') turns on the filter.  
#      Use the 1st value if the number of samples is below FILTER_FORMULA_MIN_SAMPLES
#      Use the 2nd value if the number of samples is above FILTER_FORMULA_MAX_SAMPLES
#      If the number of samples is between the MIN & MAX, a logscale is used:
#       (minVal - maxVal) * (log(maxSamples) - log(numSamples)) / (log(maxSamples) - log(minSamples)) + maxVal
FILTER_FORMULA_MIN_SAMPLES = 100
FILTER_FORMULA_MAX_SAMPLES = 1000
FILTER_WIN_INDEL = 5
FILTER_MAX_AOI = 5
FILTER_MAX_ABL = 70, 65
FILTER_MAX_STR = 20, 10
FILTER_MIN_STR = -20, -10
FILTER_MAX_STZ = 5, 10
FILTER_MIN_STZ = -5, -10
FILTER_MIN_FIC = -20, -10
FILTER_MAX_CBR = 20, 10
FILTER_MAX_LQR = 30, 20
FILTER_MIN_QUAL = 5
FILTER_MIN_MQ = 20
FILTER_MAX_MQ0 = 10

FILTER_MAX_MQ30 = 
FILTER_MAX_AOZ = 
FILTER_MAX_IOR = 

FILTER_ADDITIONAL = 

###############################################################################
## ARGUMENT FOR SVM FILTERING
###############################################################################
POS_SAMPLE = 100   # percentage of positive samples used for training
NEG_SAMPLE = 100   # percentage of negative samples used for training
SVM_CUTOFF = 0     # SVM score cutoff for PASS/FAIL
USE_SVMMODEL = FALSE   # Whether to use pre-trained model for SVM filtering
SVMMODEL =         # Pre-trained model file

###############################################################################
## ARGUMENT FOR SAMTOOLS FILTER of reads
###############################################################################
SAMTOOLS_VIEW_FILTER = -q 20 -F 0x0704 # samtools view filter (-q by MQ, -F by flag)
BAM_DEPEND = FALSE # Set to TRUE to make the BAMs dependencies in the Makefile
###############################################################################
## STEPS TO RUN : Set to TRUE to run just certain steps
##   --snpcall, --extract, --beagle, --thunder commands automatically set them
###############################################################################
RUN_INDEX = FALSE        # create BAM index file
RUN_PILEUP = FALSE       # create GLF file from BAM
RUN_GLFMULTIPLES = FALSE # create unfiltered SNP calls
RUN_VCFPILEUP = FALSE    # create PVCF files using vcfPileup and run infoCollector
RUN_FILTER = FALSE       # filter SNPs using vcfCooker
RUN_SVM = FALSE          # filter SNPs using SVM
RUN_SPLIT = FALSE        # split SNPs into chunks for genotype refinement
RUN_BEAGLE = FALSE  # BEAGLE - MUST SET AFTER FINISHING PREVIOUS STEPS
RUN_SUBSET = FALSE  # SUBSET FOR THUNDER - MAY BE SET WITH BEAGLE STEP TOGETHER
RUN_THUNDER = FALSE # THUNDER - MUST SET AFTER FINISHING PREVIOUS STEPS
RUN_SPLIT4 = FALSE   # split for BEAGLE4
RUN_BEAGLE4 = FALSE  # BEAGLE4 - MUST SET AFTER FINISHING SPLIT4
#
###############################################################################
## OPTIONS FOR GlfFlex
###############################################################################
#VCF_EXTRACT = # whole-genome (gzipped and tabixed) .vcf.gz file to extract the site information to genotype (such as 1000 Genomes site list)

#MODEL_GLFSINGLE = TRUE  # uncomment if glfSingle model is used
#MODEL_SKIP_DISCOVER = TRUE      # uncomment for disable variant discovery
#MODEL_AF_PRIOR = TRUE   # uncomment for using AF prior for genotyping
#
###############################################################################
## OPTIONS FOR EXOME/TARGETED SEQUENCING : COMMENT OUT IF WHOLE GENOME SEQUENCING
###############################################################################
#UNIFORM_TARGET_BED = $(INPUT_ROOT)/umake-example.bed # Targeted sequencing : When all individuals has the same target. Otherwise, comment it out
#MULTIPLE_TARGET_MAP =  # Target per individual : Each line contains [SM_ID] [TARGET_BED]
#SAMTOOLS_VIEW_TARGET_ONLY = TRUE # When performing samtools view, exclude off-target regions (may make command line too long)

# Exome/targeted sequencing defaults.
OFFSET_OFF_TARGET = 0 # Extend target by given # of bases 
TARGET_DIR = target   # Directory to store target information

#WGS_SVM = TRUE

###############################################################################
## BINARIES
###############################################################################
SAMTOOLS_FOR_PILEUP = $(BIN_DIR)/samtools-hybrid # for samtools pileup
SAMTOOLS_FOR_OTHERS = $(BIN_DIR)/samtools # for samtools view and calmd
GLFMERGE = $(BIN_DIR)/glfMerge # used when multiple BAMs exist per indvidual
GLFMULTIPLES = $(BIN_DIR)/glfMultiples --minMapQuality 0 --minDepth 1 --maxDepth 10000000 --uniformTsTv --smartFilter # glfMultiples and options
GLFFLEX = $(BIN_DIR)/glfFlex --minMapQuality 0 --minDepth 1 --maxDepth 10000000 --uniformTsTv --smartFilter # glfMultiples and options
VCFPILEUP = $(BIN_DIR)/vcfPileup    # vcfPileup to generate rich per-site information
INFOCOLLECTOR = $(BIN_DIR)/infoCollector # create filtering statistics
VCFMERGE = perl $(SCRIPT_DIR)/bams2vcfMerge.pl # merge multiple BAMs separated by chunk of genomes
VCFCOOKER = $(BIN_DIR)/vcfCooker  # vcfCooker for filtering
VCFSUMMARY = perl $(SCRIPT_DIR)/vcf-summary # Get summary statistics of discovered site
VCFSPLIT = perl $(SCRIPT_DIR)/vcfSplit.pl # split VCF into overlapping chunks for genotype refinement
VCFSPLIT4 = perl $(SCRIPT_DIR)/vcfSplit4.pl # split VCF into overlapping chunks for genotype refinement
VCF_SPLIT_CHROM = perl $(SCRIPT_DIR)/vcfSplitChr.pl
VCFPASTE = perl $(SCRIPT_DIR)/vcfPaste.pl # vcfPaste to generate filtered genotype VCF
BEAGLE = java -Xmx4g -jar $(BIN_DIR)/beagle.20101226.jar seed=993478 gprobs=true niterations=50 lowmem=true
BEAGLE4 = java -Xmx4g -jar $(BIN_DIR)/b4.r1219.jar seed=993478 gprobs=true
VCF2BEAGLE = perl $(SCRIPT_DIR)/vcf2Beagle.pl --PL # convert VCF (with PL tag) into beagle input
BEAGLE2VCF = perl $(SCRIPT_DIR)/beagle2Vcf.pl # convert beagle output to VCF
SVM_SCRIPT = perl $(SCRIPT_DIR)/run_libsvm.pl
SVMLEARN = $(BIN_DIR)/svm-train
SVMCLASSIFY = $(BIN_DIR)/svm-predict
INVNORM = $(BIN_DIR)/invNorm

THUNDER_STATES = --states 400 --weightedStates 300
THUNDER = $(BIN_DIR)/thunderVCF -r 30 --phase --dosage --compact --inputPhased $(THUNDER_STATES) # MaCH/Thunder genotype refinement step
LIGATEVCF = perl $(SCRIPT_DIR)/ligateVcf.pl # ligate multiple phased VCFs while resolving the phase between VCFs
LIGATEVCF4 = perl $(SCRIPT_DIR)/ligateVcf4.pl # ligate multiple phased VCFs while resolving the phase between VCFs
VCFCAT = perl $(SCRIPT_DIR)/vcfCat.pl
BGZIP = $(BIN_DIR)/bgzip
TABIX = $(BIN_DIR)/tabix
BAMUTIL = $(BIN_DIR)/bam

EXT_FILT = perl $(SCRIPT_DIR)/vcf-external-filter
EXT = 
EXT_CHR_SUB = CHR

BAMUTIL_THINNING = --phoneHomeThinning 10

#
#############################################################################
## RELATIVE DIRECTORY UNDER OUT_DIR
#############################################################################
BAM_GLF_DIR = glfs/bams   # BAM level GLF
SM_GLF_DIR = glfs/samples # sample level GLF (after glfMerge if necessary)
VCF_DIR = vcfs            # unfiltered and filtered VCF
PVCF_DIR = pvcfs          # vcfPileup results
SPLIT_DIR = split         # chunks split to multiple overlappingpieces 
BEAGLE_DIR = beagle       # beagle output
SPLIT4_DIR = split4       # chunks split to multiple overlappingpieces 
BEAGLE4_DIR = beagle4     # beagle output
THUNDER_DIR = thunder     # MaCH/thunder output
GLF_INDEX = glfIndex.ped  # glfMultiples/glfExtract index file info
#
#############################################################################
## OTHER OPTIONS
#############################################################################
UNIT_CHUNK = 5000000      # Chunk size of SNP calling : 5Mb is default
LD_NSNPS = 10000          # Chunk size of genotype refinement : 10,000 SNPs
LD_OVERLAP = 1000         # Overlapping # of SNPs between chinks : 1,000 SNPs
RUN_INDEX_FORCE = FALSE   # Regenerate BAM index file even if it exists
NOBAQ_SUBSTRINGS = SOLID  # Avoid BAQ if the BAM file contains the substring
ASSERT_BAM_EXIST = FALSE  # Check if BAM file exists
#

#-----------------------------------
# GenomeSTRiP Specific Defaults
#-----------------------------------
GENOMESTRIP_OUT = $(OUT_DIR)/sv
GENOMESTRIP_SVTOOLKIT_DIR = $(GOTCLOUD_ROOT)/src/svtoolkit
GENOMESTRIP_PARAM = $(GENOMESTRIP_SVTOOLKIT_DIR)/conf/genstrip_parameters.txt
GENOMESTRIP_MASK_FASTA = 
GENOMESTRIP_PLOIDY_MAP = 


#-----------------------------------
# General Pipeline Specific Defaults
#-----------------------------------
MAKE_BASE_NAME_PIPE = gotcloud  # basename of output Makefile $(MAKE_BASE_NAME).<type>.Makefile will be generated


#------------------------------------------------
# Defaults for a generic pipeline steps based on BAMs
#------------------------------------------------
# generic mergeBam for each sample
[bam_mergeBam]
SAMPLES = MULTI_BAM
DEPEND = BAM
DIR = $(OUT_DIR)/mergedBams
OUTPUT = $(DIR)/?(SAMPLE).bam
CMD = $(BAM_EXE) mergeBam --in ?(INPUT) --out $(OUTPUT)
INPUT_JOIN = --in 

[bam_indexBam]
DEPEND = BAM
INPUT_FILE =?(BAM)
OUTPUT = $(INPUT_FILE).bai
CMD = $(SAMTOOLS_EXE) index $(INPUT_FILE) 2> $(OUTPUT).log

[bam_recab]
DEPEND = BAM
DIR = $(OUT_DIR)/recab
OUTPUT = $(DIR)/?(SAMPLE).recal.bam
CMD = $(BAM_EXE) dedup --log $(OUTPUT).metrics --recab --in $(RECAB_INPUT) --out $(OUTPUT) --refFile $(REF) --dbsnp $(DBSNP_VCF) $(USER_PARAMS) $(BAMUTIL_THINNING)
RECAB_INPUT = ?(BAM)
USER_PARAMS =

[bam_qplot] 
DEPEND = BAM
DIR = $(OUT_DIR)/QCFiles
#LABELS = --bamlabel bam
LABELS = 
OUTPUT= $(DIR)/?(SAMPLE).qplot
MIN_MAP_QUAL = --minMapQuality 0
CMD = $(QPLOT_EXE) --reference $(REF) --dbsnp $(DBSNP_VCF) --stats $(OUTPUT).stats --Rcode $(OUTPUT).R $(MIN_MAP_QUAL) $(LABELS) ?(INPUT) 2> $(OUTPUT).err

[bam_verifyBamID]
DEPEND = PER_SAMPLE_BAM
INPUT_FILE = ?(BAM)
NEED_BAI = 1
OUTPUT= $(DIR)/?(SAMPLE).genoCheck
DIR = $(OUT_DIR)/QCFiles
PARAMS = --vcf $(HM3_VCF)
USER_PARAMS = 
CMD = $(VERIFY_BAM_ID_EXE) --bam $(INPUT_FILE) --out $(OUTPUT) $(PARAMS) $(USER_PARAMS) 2> $(OUTPUT).err


#-----------------------------------
# Indel Calling Specific Defaults
#-----------------------------------
[indel]
VT_EXE = $(BIN_DIR)/vt
OUTPUT_TYPE = + # bcf
OUTPUT_EXT = bcf
UNIT_CHUNK = 20000000  # Chunk size of indel calling : 20Mb is default
NO_CRAM = 1

STEPS = indel_mergeBam indel_indexMBam singleBamDiscover multiBamDiscover indexD merge indexM probes indexP singleBamGenotype multiBamGenotype indexG concatG indexCG mergeG indexMG concat indexC

[indelNoInterval] : indel
INTERVAL_EXT = 
INTERVAL_CMD = 

[indelChr] : indel
INTERVAL_EXT = ?(CHR).
INTERVAL_CMD = -i ?(CHR)

[indelChrPos] : indel
INTERVAL_EXT = ?(CHR).?(START).?(END).
INTERVAL_CMD = -i ?(CHR):?(START)-?(END)


#############
#0. Merging BAMs
#############
# If discovery or genotyping are broken up into intervals, 
# the merge must be done as a separate step so the merged bam can be indexed.
# Since currently genotyping is broken into intervals, the default will
# be to merge as its own set of steps.
[indel_mergeBam] : bam_mergeBam
DIR = $(OUT_DIR)/indel/mergedBams
#CMD = $(SAMTOOLS_EXE) merge $(OUTPUT) ?(INPUT)


[indel_indexMBam] : indel
DEPEND = indel_mergeBam
OUTPUT = $(INPUT_FILE).bai
CMD = $(SAMTOOLS_EXE) index $(INPUT_FILE) 2> $(OUTPUT).log
INPUT_FILE = $($(DEPEND)/OUTPUT)


#############
#1. Discovery
#############
[discoverBase] : indelNoInterval
DEPEND = BAM
DIR = $(OUT_DIR)/indel/indelvcf/?(SAMPLE)
OUTPUT = $(DIR)/?(SAMPLE).sites.$(INTERVAL_EXT)$(OUTPUT_EXT)
CMD = $(discover_CMD) | $(normalize_CMD) | $(mergedups_CMD)
VARIANT_TYPE = indels
DISCOVER_INPUT = ?(BAM)
discover_CMD = $(VT_EXE) discover -b $(DISCOVER_INPUT) -o $(OUTPUT_TYPE) -v $(VARIANT_TYPE) -r $(REF) -s ?(SAMPLE) $(INTERVAL_CMD) 2> $(DIR)/discover.$(INTERVAL_EXT)log
normalize_CMD = $(VT_EXE) normalize $(OUTPUT_TYPE) -r $(REF) -o $(OUTPUT_TYPE) 2> $(DIR)/normalize.$(INTERVAL_EXT)log
mergedups_CMD = $(VT_EXE) mergedups $(OUTPUT_TYPE) -o $(OUTPUT) 2> $(DIR)/mergedups.$(INTERVAL_EXT)log
FILELIST = $(OUT_DIR)/indel/aux/candidate_vcf_files.txt

[multiBamDiscover] : discoverBase
SAMPLES = MULTI_BAM
DEPEND = indel_indexMBam
DISCOVER_INPUT = $(indel_mergeBam/OUTPUT)
# Since genotyping is broken up by regions, we already did the merge, 
# This logic is to do it inline (which we can't do when breaking it up)
#DISCOVER_INPUT = -
#CMD = $(merge_CMD) | $(discoverBase/CMD)
#REGION = # -r ?(CHR)  Only add if this is broken by region
#merge_CMD = $(BAM_EXE) mergeBam --in ?(INPUT) --out -.ubam $(REGION)
#INPUT_JOIN = --in 

[singleBamDiscover] : discoverBase
SAMPLES = SINGLE_BAM

[indexBase] : indel
OUTPUT = $(INPUT_FILE).csi
CMD = $(VT_EXE) index $(INPUT_FILE) 2> $(OUTPUT).log
INPUT_FILE = $($(DEPEND)/OUTPUT)

[indexD] : indexBase
DEPEND = multiBamDiscover singleBamDiscover
INPUT_FILE = $(discoverBase/OUTPUT)

[merge] : indelChr
DEPEND = indexD
OUTPUT = $(DIR)/all.sites.$(INTERVAL_EXT)$(OUTPUT_EXT)
DIR = $(OUT_DIR)/indel/aux
CMD = $(VT_EXE) merge_candidate_variants -L $(discoverBase/FILELIST) -o $(OUTPUT) $(INTERVAL_CMD) 2> $(DIR)/all.sites.$(INTERVAL_EXT)$(OUTPUT_EXT).log

[indexM] : indexBase
DEPEND = merge

###############
##2. Genotyping
###############

[probes] : indelChrPos
DEPEND = merge indexM
DIR = $(OUT_DIR)/indel/aux
OUTPUT = $(DIR)/probes.sites.$(INTERVAL_EXT)$(OUTPUT_EXT)
CMD = $(VT_EXE) construct_probes $(merge/OUTPUT) -r $(REF) -o $(OUTPUT) $(INTERVAL_CMD) 2> $(DIR)/probes.$(INTERVAL_EXT)log


[indexP] : indexBase
DEPEND = probes

[genotypeBase] : indelChrPos
DEPEND = probes indexP
OUTPUT = $(DIR)/?(SAMPLE).genotypes.$(INTERVAL_EXT)$(OUTPUT_EXT)
DIR = $(discoverBase/DIR)
GENOTYPE_INPUT = ?(BAM)
CMD = $(VT_EXE) genotype -b $(GENOTYPE_INPUT) -r $(REF) -s ?(SAMPLE) -o $(OUTPUT) $(INTERVAL_CMD) $(probes/OUTPUT) 2> $(DIR)/genotype.$(INTERVAL_EXT)log
FILELIST = $(concatG/OUTPUT).list.txt

[multiBamGenotype] : genotypeBase
DEPEND = indel_indexMBam $(genotypeBase/DEPEND)
SAMPLES = MULTI_BAM
GENOTYPE_INPUT = $(indel_mergeBam/OUTPUT)
# Since genotyping is broken up by regions, we already did the merge, 
# This logic is to do it inline (which we can't do when breaking it up)
#GENOTYPE_INPUT = -
#CMD = $(merge_CMD) | $(genotypeBase/CMD)
#merge_CMD = $(BAM_EXE) mergeBam --in ?(BAM) --out -.ubam
#BAM_JOIN = --in 

[singleBamGenotype] : genotypeBase
SAMPLES = SINGLE_BAM
DEPEND = BAM $(genotypeBase/DEPEND)
GENOTYPE_INPUT = ?(BAM)

[indexG] : indexBase
DEPEND = multiBamGenotype singleBamGenotype
INPUT_FILE = $(genotypeBase/OUTPUT)


######################
#3. Merge and Annotate
######################
# Concatenate the regions
[concatG] : indelChr
DEPEND = multiBamGenotype singleBamGenotype
OUTPUT = $(DIR)/?(SAMPLE).genotypesConcat.$(INTERVAL_EXT)$(OUTPUT_EXT)
DIR = $(genotypeBase/DIR)
CMD = $(VT_EXE) concat -L $(genotypeBase/FILELIST) -o $(OUTPUT) 2> $(DIR)/concat.$(INTERVAL_EXT)log
FILELIST = $(OUT_DIR)/indel/aux/merge.$(mergeG/INTERVAL_EXT)vcf.list.txt

[indexCG] : indexBase
DEPEND = concatG

[mergeG] : indelChr
DEPEND = indexCG
OUTPUT = $(DIR)/all.genotypes.$(INTERVAL_EXT)$(OUTPUT_EXT)
DIR = $(OUT_DIR)/indel/final/merge
CMD = $(VT_EXE) merge -L $(concatG/FILELIST) -o $(OUTPUT_TYPE) | $(VT_EXE) compute_features $(OUTPUT_TYPE) -o $(OUTPUT_TYPE) 2> $(DIR)/compute_features.$(INTERVAL_EXT)log | $(VT_EXE) remove_overlap $(OUTPUT_TYPE) -o $(OUTPUT) 2> $(DIR)/remove_overlap.$(INTERVAL_EXT)log

[indexMG] : indexBase
DEPEND = mergeG

# Concatenate the regions
[concat] : indel
DEPEND = mergeG
OUTPUT_EXT = vcf.gz
OUTPUT = $(DIR)/all.genotypes.$(OUTPUT_EXT)
DIR = $(OUT_DIR)/indel/final
CMD = $(VT_EXE) concat ?(INPUT) -o $(OUTPUT) 2> $(DIR)/concat.log

[indexC] : indexBase
DEPEND = concat
OUTPUT = $(INPUT_FILE).tbi


#-----------------------------------
# Recalibration Pipeline Defaults
#-----------------------------------
[recab]
STEPS = recab_mergeBam singleBamRecab multiBamRecab recab_indexBam

[recab_mergeBam] : bam_mergeBam
DIR = $(OUT_DIR)/recab/mergedBams

[multiBamRecab] : bam_recab
SAMPLES = MULTI_BAM
DEPEND = recab_mergeBam
RECAB_INPUT = $(recab_mergeBam/OUTPUT)

[singleBamRecab] : bam_recab
SAMPLES = SINGLE_BAM

[recab_indexBam] : bam_indexBam
DEPEND = multiBamRecab singleBamRecab
INPUT_FILE = $(bam_recab/OUTPUT)


#-----------------------------------
# Recalibration with QC Pipeline Defaults
#-----------------------------------
[recabQC]
STEPS = recab_mergeBam singleBamRecab multiBamRecab recab_indexBam recabQC_qplot recabQC_verifyBamID

[recabQC_qplot] : bam_qplot
DEPEND = multiBamRecab singleBamRecab
DIR = $(OUT_DIR)/recab/QCFiles
LABELS = --bamlabel recal

[recabQC_verifyBamID] : bam_verifyBamID
DEPEND = multiBamRecab singleBamRecab recab_indexBam
DIR = $(OUT_DIR)/recab/QCFiles
INPUT_FILE = $(bam_recab/OUTPUT)


#-----------------------------------
# BAM QC Pipeline Defaults - assumes BAM has already been indexed
#-----------------------------------
[bamQC]
STEPS = bam_qplot bam_verifyBamID

#-----------------------------------
# BAM QC Pipeline, including indexing the BAM 
#-----------------------------------
[bamQC_createIndex]
STEPS = bam_qplot bam_indexBam bam_createIndex_verifyBamID

[bam_createIndex_verifyBamID] : bam_verifyBamID
DEPEND = BAM bam_indexBam
NEED_BAI = 0


#-----------------------------------
# Bam2Fastq pipeline
#-----------------------------------
[bam2fastq]
STEPS = bam2fastqStep fastqlist
IGNORE_REF_CHR_CHECK = 1

[bam2fastqStep]
DEPEND = BAM
DIR = $(OUT_DIR)/fastqs
OUTPUT = $(DIR)/?(BAM)
CMD = $(PIPE)$(BAM_EXE) bam2fastq --in $(BAM2FASTQ_INPUT) --outBase $(OUTPUT) --splitRG --gzip 2> $(OUTPUT)2fastq.log
BAM2FASTQ_INPUT = ?(BAM)
PIPE =

[fastqlist]
DEPEND = bam2fastqStep
OUTPUT = $(FASTQ_LIST)
CMD = find $(bam2fastqStep/DIR)/. -name "*.list" |xargs awk '{if(FNR != 1 || (FNR == NR)) {print $0}}' > $(OUTPUT)
LOCAL = 1

#-----------------------------------
# binBam2Fastq pipeline
#-----------------------------------
[binBam2fastq]
STEPS = binBam2fastqStep binBam2fastqlist
IGNORE_REF_CHR_CHECK = 1

[binBam2fastqStep] : bam2fastqStep
BAM2FASTQ_INPUT = -.ubam
PIPE = $(BAM_EXE) squeeze --binMid --binQualS 2,3,10,20,25,30,35,40,50 --keepDups --in ?(BAM) --out -.ubam | 

[binBam2fastqlist] : fastqlist
DEPEND = binBam2fastqStep


#-----------------------------------
# Cleanup BAM and Bam2Fastq pipeline
#-----------------------------------
[cleanUpBam2fastq]
STEPS = cleanUpBam bam2fastqStepFromClean fastqlistFromClean
IGNORE_REF_CHR_CHECK = 1

[cleanUpBam]
DEPEND = BAM
DIR = $(OUT_DIR)/fastqs/tmp.cleanUpBam
OUTPUT = $(DIR)/?(BAM)
CMD = ($(BAM_EXE) squeeze --in ?(BAM) --keepDups --rmTags AS:i,BD:Z,BI:Z,XS:i,MC:Z,MD:Z,NM:i,MQ:i --out - | $(SAMTOOLS_EXE) view -S -b -F 0x800 - | $(SAMTOOLS_SORT_EXE) sort -n -o - $(DIR)/?(BAM).temp | $(SAMTOOLS_EXE) fixmate - $(OUTPUT)) 2> $(OUTPUT)2fastq.log

[bam2fastqStepFromClean]
DEPEND = cleanUpBam
DIR = $(OUT_DIR)/fastqs
OUTPUT = $(DIR)/?(BAM)
CMD = $(BAM_EXE) bam2fastq --in $(cleanUpBam/OUTPUT) --outBase $(OUTPUT) --splitRG --readname --gzip 2> $(OUTPUT)2fastq.log

[fastqlistFromClean]
DEPEND = bam2fastqStepFromClean
OUTPUT = $(FASTQ_LIST)
CMD = find $(bam2fastqStepFromClean/DIR)/. -name "*.list" |xargs awk '{if(FNR != 1 || (FNR == NR)) {print $0}}' > $(OUTPUT)
LOCAL = 1


[global]
#############################################################################
## CLUSTER SETTING :
#############################################################################
SLEEP_MULT =     
BATCH_TYPE = 
BATCH_OPTS = 
REMOTE_PREFIX =  # REMOTE_PREFIX : Set if cluster node see the directory differently (e.g. /net/mymachine/[original-dir])

